{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disaster detection from tweets\n",
    "This was a project from a Kaggle tutorial on Deep learning for NLP. The aim of the project is to predict whether a tweet is about an actual disaster or not based on the content of the tweet\n",
    "\n",
    "[Tutorial link](https://www.kaggle.com/philculliton/nlp-getting-started-tutorial)\n",
    "\n",
    "[LSA tutorial](http://mccormickml.com/2016/03/25/lsa-for-text-classification-tutorial/)\n",
    "\n",
    "[Count Vectorizer, TF-IDF vectorizer](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "import sklearn\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-disaster tweet: I love fruits\n",
      "Ddisaster tweet: Forest fire near La Ronge Sask. Canada\n"
     ]
    }
   ],
   "source": [
    "''' Read data and look at examples of each type\n",
    "'''\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print('Non-disaster tweet: ', end='')\n",
    "print(train_df[train_df[\"target\"] == 0][\"text\"].values[1])\n",
    "\n",
    "print('Ddisaster tweet: ', end='')\n",
    "print(train_df[train_df[\"target\"] == 1][\"text\"].values[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get statistics of the dataset\n",
    "* How many training example of each category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Training dataset ======\n",
      "Disaster tweets = 3271, no disaster tweets = 4342 out of 7613 tweets\n",
      "Random assignment accuracy: 57.03\n",
      "\n",
      "If we just predicted every tweet as being disastrous, the f1-score is: 60.11\n",
      "So we should do better than this....\n"
     ]
    }
   ],
   "source": [
    "disaster = (train_df['target']==1).sum();\n",
    "no_disaster = (train_df['target']==0).sum();\n",
    "total = disaster + no_disaster\n",
    "\n",
    "print('===== Training dataset ======')\n",
    "print(f'Disaster tweets = {disaster}, no disaster tweets = {no_disaster} out of {total} tweets')\n",
    "print(f'Random assignment accuracy: {np.max((disaster, no_disaster))/total*100:0.2f}')\n",
    "\n",
    "y_true = train_df['target'];\n",
    "y_pred = np.ones_like(y_true);\n",
    "print('\\nIf we just predicted every tweet as being disastrous, the f1-score is:',end=\" \")\n",
    "print(f'{sklearn.metrics.f1_score(y_true,y_pred)*100:0.2f}')\n",
    "\n",
    "print('So we should do better than this....')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building vectors\n",
    "Let's first make a basic classifier where we use the words contained in the tweet to determine if the tweet is about a real disaster or not\n",
    "\n",
    "Below I report f1-scores for the following methods\n",
    "\n",
    "* Using scikit-learn's CountVectorizer to count the number of occurrences of every word and then classifying using a Ridge Regression\n",
    "* Using TF-IDF Vectorizer\n",
    "* Using a Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make dicts of all classifiers and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Dict of classifiers\n",
    "'''\n",
    "clf = linear_model.RidgeClassifier()\n",
    "# clf = linear_model.Lasso(alpha=1e-6); \n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5, algorithm='brute')\n",
    "clf_log = LogisticRegression(penalty='l2')\n",
    "clf_svm = svm.SVC(gamma=0.1, C=2000);\n",
    "random_forest = RandomForestClassifier(n_estimators=50,min_samples_leaf=10)\n",
    "boosted_tree = AdaBoostClassifier(n_estimators=100)\n",
    "elastic_net = LogisticRegression(penalty='elasticnet',solver = 'saga', l1_ratio = 0.5)\n",
    "\n",
    "clf_dict ={'Elastic Net': elastic_net,'Ridge':clf, 'KNN':clf_knn, 'Log Reg':clf_log, 'SVM': clf_svm, \n",
    "           'Random Forest': random_forest,'Boosted tree': boosted_tree};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Dict of features\n",
    "'''\n",
    "# Count vectorizer\n",
    "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n",
    "\n",
    "# TF-IDF\n",
    "vectorizer = feature_extraction.text.TfidfVectorizer()\n",
    "train_vectors_tfidf = vectorizer.fit_transform(train_df[\"text\"])\n",
    "\n",
    "# LSA\n",
    "svd = TruncatedSVD(100)\n",
    "train_vectors_tfidf_svd = svd.fit_transform(train_vectors_tfidf)\n",
    "\n",
    "feat = {'Count Vectorizer':train_vectors, \n",
    "       'TF IDF': train_vectors_tfidf,\n",
    "       'LSA': train_vectors_tfidf_svd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameter search for SVM. Skip this for calculating scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = np.zeros((10,12))\n",
    "for ig, g in enumerate(np.logspace(-9,9,10)):\n",
    "    for iC, C in enumerate(np.logspace(-2, 10,12)):\n",
    "        scores = model_selection.cross_val_score(svm.SVC(C=C, gamma=g), train_vectors, \n",
    "                                                 train_df[\"target\"].astype(int),cv=3, scoring='f1')\n",
    "        ss[ig,iC] = scores.mean();\n",
    "        \n",
    "plt.imshow(ss);\n",
    "plt.xticks(np.arange(0,12), np.logspace(-2, 10,12),rotation=60); \n",
    "plt.yticks(np.arange(0,10), np.logspace(-9,9,10));\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper parameter search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame();\n",
    "for (key, item) in clf_dict.items():\n",
    "    for (key_f, item_f) in feat.items():\n",
    "        scores = model_selection.cross_val_score(item, item_f, \n",
    "                                                 train_df[\"target\"].astype(int),cv=3, scoring='f1')\n",
    "        df_scores = df_scores.append({'Features':key_f,'Classifier':key,\n",
    "                                  'f1':np.mean(scores)},ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not much better than random assignment accuracy of 57%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) TF-IDF Vectorizer + Ridge Regression\n",
    "Count Vectorizer weighs each word equally, but there might be some words that are present often but do not provide much information about the content, e.g., 'a', 'the' etc. In order to account for that, we can use a different vectorizer called TF-IDF, where each terms's frequency $(tf)$ is multiplied by $idf$ or inverse-document frequency. If a word occurs in a lot of documents (here, tweets), then it's idf is low and vice-versa\n",
    "\n",
    "In short, the rarer a word, the higher is its TF-IDF score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Latent Semantic Analysis (LSA)\n",
    "LSA is basically a version of TF-IDF with reduced dimensionality via SVD decomposition. It preserves the high variance features and removes the high frequency features.\n",
    "\n",
    "Interestingly, the performance is lower with LSA suggesting that the high frequency/low variance terms are important in classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Features</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elastic Net</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>0.629034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elastic Net</td>\n",
       "      <td>TF IDF</td>\n",
       "      <td>0.593359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elastic Net</td>\n",
       "      <td>LSA</td>\n",
       "      <td>0.627579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>0.608267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>TF IDF</td>\n",
       "      <td>0.643475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>LSA</td>\n",
       "      <td>0.634295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>0.159711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN</td>\n",
       "      <td>TF IDF</td>\n",
       "      <td>0.612973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN</td>\n",
       "      <td>LSA</td>\n",
       "      <td>0.522100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Log Reg</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>0.646067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Log Reg</td>\n",
       "      <td>TF IDF</td>\n",
       "      <td>0.632608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Log Reg</td>\n",
       "      <td>LSA</td>\n",
       "      <td>0.617410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>0.617608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVM</td>\n",
       "      <td>TF IDF</td>\n",
       "      <td>0.625463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LSA</td>\n",
       "      <td>0.653677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>0.552649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>TF IDF</td>\n",
       "      <td>0.533860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>LSA</td>\n",
       "      <td>0.588381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Boosted tree</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>0.549200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Boosted tree</td>\n",
       "      <td>TF IDF</td>\n",
       "      <td>0.537344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Boosted tree</td>\n",
       "      <td>LSA</td>\n",
       "      <td>0.604001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Classifier          Features        f1\n",
       "0     Elastic Net  Count Vectorizer  0.629034\n",
       "1     Elastic Net            TF IDF  0.593359\n",
       "2     Elastic Net               LSA  0.627579\n",
       "3           Ridge  Count Vectorizer  0.608267\n",
       "4           Ridge            TF IDF  0.643475\n",
       "5           Ridge               LSA  0.634295\n",
       "6             KNN  Count Vectorizer  0.159711\n",
       "7             KNN            TF IDF  0.612973\n",
       "8             KNN               LSA  0.522100\n",
       "9         Log Reg  Count Vectorizer  0.646067\n",
       "10        Log Reg            TF IDF  0.632608\n",
       "11        Log Reg               LSA  0.617410\n",
       "12            SVM  Count Vectorizer  0.617608\n",
       "13            SVM            TF IDF  0.625463\n",
       "14            SVM               LSA  0.653677\n",
       "15  Random Forest  Count Vectorizer  0.552649\n",
       "16  Random Forest            TF IDF  0.533860\n",
       "17  Random Forest               LSA  0.588381\n",
       "18   Boosted tree  Count Vectorizer  0.549200\n",
       "19   Boosted tree            TF IDF  0.537344\n",
       "20   Boosted tree               LSA  0.604001"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.42466887, 0.29617193])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1000, input_dim=21637, activation='relu'))\n",
    "    model.add(Dense(20, input_dim=1000, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "idx_sort_tgt = np.argsort(train_df['target'])\n",
    "sort_values = train_df['target'][idx_sort_tgt].values;\n",
    "sort_train = train_vectors[idx_sort_tgt,:].toarray()\n",
    "\n",
    "scores = model_selection.cross_val_score(model, sort_train, sort_values, cv=3,scoring=\"f1\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = df_scores.append({'Classifier':'MLP','Features':'Count Vectorizer','f1':np.mean(scores)},ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
